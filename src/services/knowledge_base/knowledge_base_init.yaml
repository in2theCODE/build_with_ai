#!/usr/bin/env python3
  """
Knowledge Base Initializer for the Neural Code Generator.

This script initializes the vector knowledge base with code examples
for retrieval-augmented generation.
"""

    import os
    import sys
    import glob
    import argparse
    import logging
    import torch
    from pathlib import Path
    from tqdm import tqdm
    from concurrent.futures import ThreadPoolExecutor, as_completed
    from sentence_transformers import SentenceTransformer
    import json
  
  # Configure logging
    logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger("knowledge_base_initializer")
  
  # Add the module path to the Python path
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))

  # Try to import the vector knowledge base
  try:
    from program_synthesis_system.services.knowledge_base.vector_knowledge_base import VectorKnowledgeBase
  except ImportError:
    logger.warning("VectorKnowledgeBase not found, using simplified implementation")
    VectorKnowledgeBase = None


  class SimpleKnowledgeBase:
      """Simple implementation of a vector knowledge base for code examples."""

        def __init__(self, storage_path, embedding_model):
            """Initialize the simple knowledge base."""
              self.storage_path = Path(storage_path)
              self.storage_path.mkdir(parents=True, exist_ok=True)
              self.embedding_model = embedding_model
              self.index_path = self.storage_path / "index.json"
              self.index = {}
              self._load_index()

        def _load_index(self):
            """Load the index from disk if it exists."""
              if self.index_path.exists():
                try:
                  with open(self.index_path, 'r') as f:
                    self.index = json.load(f)
                  logger.info(f"Loaded {len(self.index)} entries from index")
                except Exception as e:
                  logger.error(f"Error loading index: {e}")
    
    def _save_index(self):
        """Save the index to disk."""
              try:
                with open(self.index_path, 'w') as f:
                  json.dump(self.index, f)
                logger.info(f"Saved {len(self.index)} entries to index")
              except Exception as e:
                logger.error(f"Error saving index: {e}")
    
    def add(self, item_id, code, metadata=None):
        """Add a code example to the knowledge base."""
              try:
                # Generate embedding for the code
                embedding = self.embedding_model.encode(code, normalize_embeddings=True)
                
                # Store the code, embedding, and metadata
                item_data = {
                "code": code,
                "embedding": embedding.tolist(),
                "metadata": metadata or {}
              }

        ===========
                self.index[item_id] = item_data

                # Save the vector to a file (for larger examples)
                if len(code) > 1000:
                  code_path = self.storage_path / f"{item_id}.py"
                  with open(code_path, 'w') as f:
                    f.write(code)
                  item_data["file_path"] = str(code_path)

                return True
              except Exception as e:
                logger.error(f"Error adding item {item_id}: {e}")
            return False
    
    def commit(self):
        """Commit the changes to disk."""
              self._save_index()


  def parse_args():
      """Parse command line arguments."""
        parser = argparse.ArgumentParser(description="Knowledge Base Initializer")
        parser.add_argument("--source-dir", "-s", required=True,
        help="Directory containing source code examples")
        parser.add_argument("--output-dir", "-o", required=True,
        help="Output directory for the knowledge base")
        parser.add_argument("--embedding-model", "-m", default="all-mpnet-base-v2",
        help="Embedding model to use")
        parser.add_argument("--batch-size", "-b", type=int, default=32,
        help="Batch size for processing")
        parser.add_argument("--file-types", "-f", default="py,js,ts,java,cpp,c,go,rs",
        help="Comma-separated list of file extensions to process")
        parser.add_argument("--verbose", "-v", action="store_true",
        help="Enable verbose output")
        return parser.parse_args()


  def read_code_file(file_path):
      """Read a code file and return its content."""
        try:
          with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
          return content
        except Exception as e:
          logger.error(f"Error reading file {file_path}: {e}")
        return None


def find_code_files(source_dir, file_types):
    """Find all code files in the source directory."""
        extensions = file_types.split(',')
        files = []

        for ext in extensions:
          pattern = os.path.join(source_dir, f"**/*.{ext}")
          files.extend(glob.glob(pattern, recursive=True))

        logger.info(f"Found {len(files)} code files with extensions: {file_types}")
    return files


def get_language_from_extension(file_path):
    """Get the programming language from the file extension."""
        ext = os.path.splitext(file_path)[1].lower()
        language_map = {
        '.py': 'python',
        '.js': 'javascript',
        '.ts': 'typescript',
        '.java': 'java',
        '.cpp': 'cpp',
        '.c': 'c',
        '.go': 'go',
        '.rs': 'rust'
  }
        return language_map.get(ext, 'unknown')


  def process_code_files(files, kb, embedding_model, batch_size):
      """Process code files and add them to the knowledge base."""
        num_files = len(files)
        processed = 0
        added = 0

    # Process files in batches
        for i in range(0, num_files, batch_size):
          batch = files[i:i+batch_size]

          # Use ThreadPoolExecutor for parallel processing
          with ThreadPoolExecutor(max_workers=min(batch_size, 16)) as executor:
            # Submit tasks
            future_to_file = {
            executor.submit(read_code_file, file_path): file_path
            for file_path in batch
          }

            # Process results
            for future in as_completed(future_to_file):
              file_path = future_to_file[future]
              try:
                content = future.result()
                processed += 1

                if content is None or len(content.strip()) < 10:
                  continue

                # Generate a unique ID for the code example
                item_id = f"code_{processed:06d}"
                
                # Get the language from the file extension
                language = get_language_from_extension(file_path)
                
                # Add to the knowledge base with metadata
                metadata = {
                "source_file": os.path.basename(file_path),
                "language": language,
                "size": len(content)
              }

                success = kb.add(item_id, content, metadata)
                if success:
                  added += 1

                # Commit changes periodically
                if added % 100 == 0:
                  kb.commit()
                  logger.info(f"Progress: {processed}/{num_files} processed, {added} added")

              except Exception as e:
                logger.error(f"Error processing {file_path}: {e}")
        
    # Final commit
    kb.commit()
    logger.info(f"Completed: {processed}/{num_files} processed, {added} added")
        return added


  def main():
      """Main entry point for the script."""
        args = parse_args()

    # Set log level
        if args.verbose:
          logging.getLogger().setLevel(logging.DEBUG)

        logger.info(f"Initializing knowledge base in {args.output_dir}")
        logger.info(f"Using embedding model: {args.embedding_model}")
    
    # Initialize the embedding model
    try:
        embedding_model = SentenceTransformer(args.embedding_model)
        logger.info(f"Loaded embedding model: {args.embedding_model}")
    except Exception as e:
        logger.error(f"Failed to load embedding model: {e}")
        return 1
    
    # Initialize the knowledge base
    try:
        if VectorKnowledgeBase is not None:
            kb = VectorKnowledgeBase(
                storage_type="file",
                                                                                                                                                                                                file_storage_path=args.output_dir,
                                                                                                                                                                                                embedding_model=args.embedding_model,
                                                                                                                                                                                                similarity_threshold=0.75
                                                                                                                                                                                                )
                                                                                                                                                                                                logger.info("Using VectorKnowledgeBase implementation")
                                                                                                                                                                                                else:
                                                                                                                                                                                                  kb = SimpleKnowledgeBase(args.output_dir, embedding_model)
                                                                                                                                                                                                  logger.info("Using SimpleKnowledgeBase implementation")
        except Exception as e:
          logger.error(f"Failed to initialize knowledge base: {e}")
        return 1
    
    # Find code files
    files = find_code_files(args.source_dir, args.file_types)
    if not files:
        logger.error(f"No code files found in {args.source_dir}")
          return 1

    # Process code files
        num_added = process_code_files(files, kb, embedding_model, args.batch_size)

        logger.info(f"Knowledge base initialization completed: {num_added} examples added")
        return 0


  if __name__ == "__main__":
    # Clear CUDA cache if available
    if torch.cuda.is_available():
      torch.cuda.empty_cache()

    sys.exit(main())